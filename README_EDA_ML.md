# 묘목 생존율 예측 모델 프로젝트

## 프로젝트 개요
본 프로젝트는 묘목의 생존율을 예측하기 위한 머신러닝 모델을 개발하는 프로젝트입니다.
초기의 단순 분류 모델에서 시작하여, 시간에 따른 생존율을 예측할 수 있는 고도화된 생존 분석 모델까지 구현하였습니다.

## 목차
1. [EDA를 기반으로 한 데이터 전처리](#1-eda를-기반으로-한-데이터-전처리)
2. [분류 모델을 이용한 묘목의 생존 여부 예측](#2-분류-모델을-이용한-묘목의-생존-여부-예측)
3. [기존 모델의 한계 및 새로운 모델 기획](#3-기존-모델의-한계-및-새로운-모델-기획)
4. [시간에 따른 생존율을 예측하는 모델 구현 및 평가](#4-시간에-따른-생존율을-예측하는-모델-구현-및-평가)
5. [모델 평가 방식과 성능 고도화 기법](#5-모델-평가-방식과-성능-고도화-기법)
6. [트러블 슈팅](#6-트러블-슈팅)

---

## 1. EDA를 기반으로 한 데이터 전처리

### 데이터 개요
EDA를 통해 분석한 데이터를 기반으로 데이터 전처리 및 인코딩을 수행하였습니다.

### 주요 특성(Features) 및 라벨(Labels)

| 변수명 | 설명 |
|--------|------|
| **Species** | 나무 종명 |
| **Light_ISF** | 조도 (받는 햇빛의 양) |
| **Light_Cat** | 빛의 세기 |
| **Soil** | 토양의 출처 |
| **Sterile** | 토양의 살균 여부 |
| **Conspecific** | 토양의 타입 (동종에서 채취한 토양, 이종에서 채취한 토양,...) |
| **Myco** | 나무에서 발견되는 균의 종류 |
| **SoilMyco** | 토양에서 발견되는 균의 종류 |
| **PlantDate** | 식재일 |
| **AMF** | AMF균의 비율 |
| **EMF** | EMF균의 비율 |
| **Phenolics** | 페놀 화합물의 함유량 |
| **Lignin** | 리그닌의 비율 |
| **NSC** | NSC의 비율 |
| **Time** | 사건(사망 혹은 측정 종료)가 발생한 시간 |
| **Alive** | 사건 종류 (생존/사망) |

### 전처리 과정
다음과 같은 순서로 데이터 전처리를 진행하였습니다:

```
데이터 드랍 → 이상치 처리 → 결측치 처리 → 날짜값 통일 → 라벨 데이터 통합 → 인코딩
```

**[데이터 분포 시각화 자료 위치]**
> *데이터의 분포, 결측치 현황, 이상치 탐지 결과 등의 시각화 자료*

---

## 2. 분류 모델을 이용한 묘목의 생존 여부 예측

### 모델링 목표

분류 모델을 이용하여 2 성장기가 지난 묘목(약 120일 후)의 생존율을 예측합니다.

2 성장기가 지나면 생존율이 매우 안정화되므로, 해당 기간까지의 생존율 예측이 매우 중요합니다.

**[실제 묘목의 생존율 그래프 위치]**
> *시간에 따른 묘목 생존율 변화를 보여주는 그래프*

### 사용 모델
3개의 분류 모델을 사용하여 분류를 수행하였습니다:

#### 1. Logistic Regression
**[Logistic Regression 결과 시각화 위치]**
> *모델 성능 지표, ROC 곡선, 특성 중요도 등*

**주요 결과:**
- 정확도: [수치]
- 정밀도: [수치]
- 재현율: [수치]
- F1-score: [수치]

#### 2. Random Forest
**[Random Forest 결과 시각화 위치]**
> *모델 성능 지표, 특성 중요도, 트리 구조 등*

##### 2.1. 기본 랜덤포레스트
```python
# 랜덤포레스트 모델 생성
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# 학습
rf.fit(X_train, y_train)

# 훈련모델 평가 출력
train_model_evaluation(rf, X_train, y_train, X_test, y_test)
# 평가지표 출력
evaluate_binary_classification(y_test, y_pred)
```
```sh
Training Score  : 0.9602704987320372
Testing  Score  : 0.8269230769230769
Cross Validation Score : 0.7734400228365492
===============================================================
Accuracy        : 0.8269230769230769
Confusion Matrix:
 [[291  28]
 [ 44  53]]
Precision       : 0.654320987654321
Recall          : 0.5463917525773195
F1 Score        : 0.5955056179775281
```
##### 2.2. KFold 랜덤포레스트
```python
# KFold 교차 검증
from sklearn.model_selection import KFold

# 5개의 폴드로 나누고 랜덤하게 섞음
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
```
```sh
Training Score  : 0.9294167371090448
Testing  Score  : 0.7864693446088795
Cross Validation Score : 0.7734400228365492
===============================================================
Accuracy        : 0.7864693446088795
Confusion Matrix:
 [[320  37]
 [ 64  52]]
Precision       : 0.5842696629213483
Recall          : 0.4482758620689655
F1 Score        : 0.5073170731707317
```
##### 2.3. StratifiedKFold 랜덤포레스트
```python
# StratifiedKFold 교차 검증
from sklearn.model_selection import StratifiedKFold

skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
```
```sh
Training Score  : 0.9289940828402367
Testing  Score  : 0.7949260042283298
Cross Validation Score : 0.7734400228365492
===============================================================
Accuracy        : 0.7949260042283298
Confusion Matrix:
 [[323  38]
 [ 59  53]]
Precision       : 0.5824175824175825
Recall          : 0.4732142857142857
F1 Score        : 0.5221674876847291
```
##### 2.4. GridSearchCV 랜덤포레스트
```python
# GridSearchCV 사용
from sklearn.model_selection import GridSearchCV

# 하이퍼 파라미터 튜닝을 위한 그리드 탐색 범위 정의
param_grid = {
    'n_estimators': [100, 200, 300],  # 트리 개수
    'max_depth': [None, 5, 10, 20],   # 트리 최대 깊이
    'min_samples_split': [2, 5, 10],  # 내부 노드를 분할하는 데 필요한 최소 샘플 수
    'min_samples_leaf': [1, 2, 4],    # 리프 노드가 되기 위한 최소 샘플 수
    'max_features': ['auto', 'sqrt', 'log2']  # 각 분할에서 고려할 최대 특성 수
}

grid = GridSearchCV(rf, param_grid, scoring='accuracy', cv=5, n_jobs=-1)

grid.fit(X_train, y_train)
```
```sh
최적의 파라미터             : {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}
최적의 파라미터로 학습된 모델: RandomForestClassifier(min_samples_split=10, random_state=42)
최적화된 정확도 점수        : 0.7861241202130221
```

**주요 결과:**
- 정확도: [수치]
- 정밀도: [수치]
- 재현율: [수치]
- F1-score: [수치]

#### 3. XGBoost
**[XGBoost 결과 시각화 위치]**
> *모델 성능 지표, 특성 중요도, 학습 곡선 등*

##### 3.1. 기본 XGBoost
```python
# XGB 모델 생성
xgb_clf = XGBClassifier(
    n_estimators=100,
    max_depth=3,
    learning_rate=0.1,
    random_state=42, 
    enable_categorical=True 
)

# 학습
xgb_clf.fit(X_train, y_train)

# 훈련모델 평가 출력
train_model_evaluation(xgb_clf, X_train, y_train, X_test, y_test)

# 평가지표 출력
evaluate_binary_classification(y_test, y_pred)
```
```sh
Training Score  : 0.8415046491969569
Testing  Score  : 0.8173076923076923
Cross Validation Score : 0.776831607211354
======================================================================================================================================================
Accuracy        : 0.8173076923076923
Confusion Matrix:
 [[286  27]
 [ 49  54]]
Precision       : 0.6666666666666666
Recall          : 0.5242718446601942
F1 Score        : 0.5869565217391305
```
**주요 결과:**
- 정확도: [수치]
- 정밀도: [수치]
- 재현율: [수치]
- F1-score: [수치]

**[모델 비교 분석 시각화 위치]**
> *3개 모델의 성능 비교 차트, 혼동행렬 비교 등*

---

## 3. 기존 모델의 한계 및 새로운 모델 기획

### 기존 모델의 한계점
- 기존 모델은 관측 종료 시점(해당 데이터에서는 115.5일 후)에서의 생존 여부만 예측 가능
- 실무에서는 다양한 시기의 생존율을 예측해야 할 필요가 있고, 또한 적은 데이터만을 가지고 예측하기도 해야 함

### 새로운 접근 방향
1. **모델의 일부 특성만을 이용한 모델 구현** (특성 선택 이용)
2. **생존율을 시간에 따라 예측할 수 있는 모델 구현**

**[기존 모델 vs 새로운 모델 비교 다이어그램 위치]**
> *두 접근 방식의 차이점을 보여주는 개념도*

---

## 4. 시간에 따른 생존율을 예측하는 모델 구현 및 평가

### 모델링 목표
단순히 생존 여부만을 판단하는 모델이 아니라, 시간에 따른 개체별 위험도와 주기적인 관찰이 필요한 개체 등을 구분하기 위해서는 시간에 따른 생존 곡선을 그릴 수 있는 모델이 필요합니다.

### 구현 모델
다음 두 모델을 기반으로 평가를 진행하였습니다:

#### 1. XGBoost with Cox
**[XGBoost with Cox 모델 결과 시각화 위치]**
> *생존 곡선, 위험도 점수 분포, 성능 지표 등*

#### 2. Random Survival Forest (RSF)
**[Random Survival Forest 결과 시각화 위치]**
> *생존 곡선, 위험도 점수 분포, 성능 지표 등*

### 모델 평가 결과
위 두 모델을 기반으로 평가한 결과, **RSF가 좋은 성능**을 보였습니다.

**[최종 모델 평가 결과 시각화 위치]**
> *생존 확률 그래프, 혼동 행렬, 모델 비교 결과 등*

### 결과 분석
- 위 모델을 기반으로 생존 확률 그래프, 혼동 행렬 등을 출력하고 모델 평가 및 결과 분석을 수행하였습니다.

---

## 5. 모델 평가 방식과 성능 고도화 기법

### 평가 방식
1. **생존율 모델에서 threshold를 이용한 이진 분류 후 정확도 평가**
2. **KFold를 이용한 모델의 정확도 측정**
3. **GridSearchCV를 이용한 최적의 파라미터 탐색**

**[모델 평가 과정 시각화 위치]**
> *K-fold 교차검증 결과, 하이퍼파라미터 튜닝 과정 등*

### 성능 고도화 기법
**[최적화 결과 비교 시각화 위치]**
> *파라미터 튜닝 전후 성능 비교, 최적 파라미터 조합 등*

---

## 6. 트러블 슈팅

### 주요 해결 과제들

#### 1. 생존율 모델 평가 방식의 문제
**문제점:**
- 생존율 모델의 경우 위험 점수를 기반으로 한 평가 방식으로는 기존 모델과 비교 불가

**해결책:**
- 위험 점수를 기반으로 모델을 이진 분류한 후 정확도를 계산하는 방식으로 기존 모델과 비교

#### 2. 생존율 모델의 입력 데이터 구조 문제
**문제점:**
- 생존율 모델의 경우, 특성, 사건 발생 또는 관측 종료 시간, 사건 발생 여부 3개의 데이터를 모델에 전달
- GridSearchCV 등은 모두 X, y 만을 받는 모델을 기반으로 함

**해결책:**
- 인자를 2개 (특성, 시간과 사건) 혹은 3개로 모두 받을 수 있도록 메소드 디자인

#### 3. 분류 라벨링의 직관성 문제
**문제점:**
- 생존율 예측 → 생존: 1, 사망: 0으로 분류하는 것이 자연스럽지만, 때문에 사건 발생인 사망이 0으로 분류되어 confusion matrix를 기반으로 한 평가 지표에 오류 발생

**해결책:**
- 해당 함수를 새로 정의하여 해결

**[트러블 슈팅 과정 시각화 위치]**
> *문제 해결 전후 비교, 새로운 평가 함수의 결과 등*

---

## 결론 및 향후 과제

### 주요 성과
1. 단순 분류 모델에서 시작하여 시간에 따른 생존율을 예측하는 고도화된 모델까지 구현
2. Random Survival Forest 모델이 가장 우수한 성능을 보임
3. 실무에 적용 가능한 다양한 시점에서의 생존율 예측 모델 완성

### 향후 개선 방향
- 더 적은 특성을 사용한 모델의 성능 검증
- 실시간 데이터 수집 환경에서의 모델 성능 평가
- 다양한 환경 조건에서의 모델 일반화 성능 향상

---

## 기술 스택
- **데이터 분석**: Python, Pandas, NumPy
- **시각화**: Matplotlib, Seaborn
- **머신러닝**: Scikit-learn, XGBoost
- **생존 분석**: lifelines, scikit-survival
- **모델 평가**: KFold, GridSearchCV

## 데이터셋 정보
- **Tree_Data.csv**: 원본 데이터 (2,783행 × 24열)
- **Tree_Data_processing.csv**: 전처리된 데이터 (2,783행 × 16열)

